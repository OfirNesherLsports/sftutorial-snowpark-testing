{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "codeCollapsed": false
   },
   "source": "import snowflake.snowpark as snowpark\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.snowpark.functions import col, call_builtin, cast\nfrom utils import *\n\n\nsession = get_active_session()\n\n# CONSTANTS\nBRONZE_TABLE_NAME = \"BRONZE_RESULTING.INPLAY_RESULTING_MARKETS\"\nSILVER_TABLE_NAME = BRONZE_TABLE_NAME.replace(\"BRONZE\", \"SILVER\", 1)\n\n\ndef restructure_silver(df):\n    \"\"\"\n    Filter and restructure the inplay_resulting_markets DataFrame.\n    \"\"\"\n\n    fixturemarket_list = [\n        \"Bets\",\n        \"CreationDate\",\n        \"RobotId\",\n        \"ProviderFixtureId\",\n        \"ProviderId\",\n        \"MessageGuid\",\n        \"ProviderMarketId\",\n        \"MarketId\",\n        \"FixtureId\",\n        \"LastUpdate\",\n        \"ProcessingGuid\",\n        # What did we say about 'Market'?\n    ]\n    root_list = [\n        \"SETTLEMENTSINPLAY\",\n        \"SPORTID\",\n        \"SETTLEMENTSPOSTMATCH\",\n        \"LEAGUEID\",\n        \"LOCATIONID\",\n        \"LIVESCOREGUID\",\n        '\"TOPIC-NAME\"',\n        \"ISOUTRIGHT\",\n        \"FIXTURESTATUS\",\n        \"CURRENT_TIMESTAMP\",\n    ]\n\n    try:\n        print(f\"Starting {BRONZE_TABLE_NAME} DataFrame processing\")\n\n        # Create a list of column selections\n        select_columns = [\n            df[\"FIXTUREMARKET\"][field].alias(field) for field in fixturemarket_list\n        ] + [df[field2].alias(field2) for field2 in root_list]\n\n        print(f\"select_columns: {select_columns}\")\n        print(f\"{BRONZE_TABLE_NAME} DataFrame processed successfully\")\n\n        delta_df = df.select(*select_columns)\n        delta_df = delta_df.withColumn(\"Bets\", cast(delta_df.Bets, StructType()))\n        delta_df = delta_df.withColumnRenamed(\n                \"CURRENT_TIMESTAMP\", \"KAFKA_TIMESTAMP\"\n            )\n        \n        return delta_df\n\n    except Exception as e:\n        print(\n            f\"An error occurred during {BRONZE_TABLE_NAME} DataFrame processing: {str(e)}\"\n        )\n        raise\n\n\ndef main(session: snowpark.Session):\n    try:\n        print(\"Starting the ETL process\")\n        last_update_date = find_last_update_date(session, BRONZE_TABLE_NAME)\n        df, delta_count = find_delta(session, BRONZE_TABLE_NAME, last_update_date)\n\n        if delta_count == 0:\n            print(\"No new data to process. ETL process completed successfully.\")\n            return\n        else:\n            latest_timestamp = find_latest_timestamp(df)\n            delta_df = restructure_silver(df)\n            delta_df_no_null, null_count = remove_null_rows(delta_df)\n            # count_duplicates_removed = update_silver(\n                # session, delta_df_no_null, SILVER_TABLE_NAME\n            # )\n\n            # append new data (delta_df) to table {SILVER_TABLE_NAME}\n            delta_df_no_null.write.mode(\"append\").save_as_table(SILVER_TABLE_NAME)\n\n            update_config(session, BRONZE_TABLE_NAME, latest_timestamp)\n            # save_metrics(\n            #     session,\n            #     BRONZE_TABLE_NAME,\n            #     delta_count,\n            #     count_duplicates_removed,\n            #     null_count,\n            #     latest_timestamp,\n            # )\n            print(\n                f\"ETL process completed successfully. Latest timestamp processed: {latest_timestamp}\"\n            )\n    except Exception as e:\n        print(f\"An error occurred during the ETL process: {str(e)}\")\n        raise\n\n\nif __name__ == \"__main__\":\n    main(session)\n",
   "execution_count": null,
   "outputs": []
  }
 ]
}